{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"autoencoder_ronnie.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"wXfsmvNVG-qo","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","from sklearn import preprocessing\n","from keras.models import Model, load_model\n","from keras.layers import Input, Dense, Dropout\n","from keras import regularizers\n","from sklearn.model_selection import train_test_split\n","from keras.callbacks import EarlyStopping\n","from sklearn import metrics\n","import matplotlib.pyplot as plt\n","\n","\n","import time\n","import copy\n","import math"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rn-K6GynHc7J","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","path = '/content/drive/My Drive/attack detection/project/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2mjrmiLrHGqO","colab_type":"text"},"source":["# Read the data"]},{"cell_type":"code","metadata":{"id":"KDGtvRwpHFdp","colab_type":"code","colab":{}},"source":["sync_method = ['averaging', 'oversampling', 'downsampling']\n","num_of_changed_features = ['2', '3']\n","normalizing_method = ['min_max', 'standard']\n","\n","sync_method = sync_method[0] \n","num_of_changed_features = num_of_changed_features[1]\n","normalizing_method = normalizing_method[1]\n","\n","data_df = pd.read_csv(path + 'data/sync_data_' + sync_method + '_anomal_' + num_of_changed_features + '_' + normalizing_method + '.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hiziEkR9HeAC","colab_type":"code","colab":{}},"source":["data_df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z605cSyvKAAv","colab_type":"text"},"source":["# Split to train test - train include only normal data and test include only anomalies data"]},{"cell_type":"code","metadata":{"id":"xgmzX1MWqLra","colab_type":"code","colab":{}},"source":["x_data = data_df.iloc[:,:-1]\n","y_data = data_df.iloc[:,-1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xTxw5BgcqQlr","colab_type":"code","colab":{}},"source":["x_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-8z8WN4WqSTv","colab_type":"code","colab":{}},"source":["y_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lu4OVzLaOwzO","colab_type":"code","colab":{}},"source":["train_idx = y_data[y_data==0.0].index.values\n","\n","x_train = x_data.iloc[train_idx]\n","y_train = y_data[train_idx]\n","x_test = x_data \n","y_test = y_data "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PaOxEWOqbQx","colab_type":"code","colab":{}},"source":["x_train.head()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U1e68so3O6Xj","colab_type":"text"},"source":["# Autoencoder"]},{"cell_type":"code","metadata":{"id":"2HK1M6NjLYns","colab_type":"code","colab":{}},"source":["nb_epoch = 500\n","batch_size = 64\n","\n","\n","# Input dimension size (first and last autoencoder layer size)\n","input_dim = x_train.shape[1]\n","\n","# Setting the auto encoder layers\n","input_layer = Input(shape=(input_dim, ))\n","\n","encoder = Dense(4, activation=\"relu\")(input_layer) \n","\n","encoder = Dense(2, activation=\"relu\")(encoder) \n","\n","decoder = Dense(4, activation=\"relu\")(encoder)\n","\n","decoder = Dense(input_dim, activation='sigmoid')(decoder) \n","\n","autoencoder = Model(inputs=input_layer, outputs=decoder)\n","\n","autoencoder.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KMPsSyGXQ78J","colab_type":"code","colab":{}},"source":["# Configures the learning process of the network\n","autoencoder.compile(optimizer='adam',loss='mean_squared_error',metrics=['mse'])\n","\n","# Train the autoencoder based on the best epoch, returns history object\n","history = autoencoder.fit(x_train, x_train, epochs=nb_epoch, batch_size=batch_size, verbose=2, validation_split=0.1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ziopvHSkYFcy","colab_type":"code","colab":{}},"source":["# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Train', 'Val'], loc='upper left')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JCvC8WawRCg5","colab_type":"code","colab":{}},"source":["# Predictions and results for the TEST set\n","\n","predictions = autoencoder.predict(x_test)\n","square_errors = np.power(x_test - predictions, 2)\n","mse = np.mean(square_errors, axis=1)\n","mse_series = pd.Series(mse)\n"," \n","most_anomal_trx = mse_series.sort_values(ascending=False)\n","columns=[\"id\", \"mse_all_columns\", \"label\"]\n","items = []\n","for x in most_anomal_trx.iteritems():\n","    item = [x[0], x[1], 1]\n","    items.append(item)\n","    \n","df_anomal_trx = pd.DataFrame(items, columns=columns)\n","df_anomal_trx.set_index('id', inplace=True)\n","\n","y_pred = df_anomal_trx.head(y_data[y_data==1.0].shape[0])\n","y_true = y_test[y_pred.index]\n","\n","print('found ' + str(y_true.sum()) + ' anomalies out of ' + str(y_data[y_data==1.0].shape[0]))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l6lUv0F_sljN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}